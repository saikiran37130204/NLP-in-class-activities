{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyObjXd2a2bAn8pVjoYZ3l71",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saikiran37130204/NLP-in-class-activities/blob/main/NLP_Activity1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-wHZy5Bj-4-",
        "outputId": "078978a4-4c32-4f25-8caf-799c53533963"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "saikiran 24\n"
          ]
        }
      ],
      "source": [
        "str= \"saikiran 24\";\n",
        "print(str)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n",
        "import nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btW8u6cAlITv",
        "outputId": "00699b95-8083-44a4-8198-0676d17659a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9k47GI6blTh8",
        "outputId": "5fe7fbc8-63a7-44d9-b252-28f3a1e1a70e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!conda install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdPksoXxlZQQ",
        "outputId": "a1d6d64b-db87-4d0e-e714-abe4ab0f9409"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: conda: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Natural language processing (NLP) is a subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human language, in particular how to program computers to process and analyze large amounts of natural language data.\"\n",
        "\n",
        "# Tokenize the text\n",
        "tokens = nltk.word_tokenize(text)\n",
        "\n",
        "print(\"tokens:\",tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVL1wX89lm97",
        "outputId": "251d98d9-03fc-4571-9715-2e5af8d9d414"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tokens: ['Natural', 'language', 'processing', '(', 'NLP', ')', 'is', 'a', 'subfield', 'of', 'linguistics', ',', 'computer', 'science', ',', 'and', 'artificial', 'intelligence', 'concerned', 'with', 'the', 'interactions', 'between', 'computers', 'and', 'human', 'language', ',', 'in', 'particular', 'how', 'to', 'program', 'computers', 'to', 'process', 'and', 'analyze', 'large', 'amounts', 'of', 'natural', 'language', 'data', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sai=\"sai kiran is learing nlp.\";\n",
        "\n",
        "token=nltk.word_tokenize(sai);\n",
        "\n",
        "print(\"tokens:\",token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSgpPnRpm7zL",
        "outputId": "d68721d6-1489-401c-e6a7-b02a7b82034e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tokens: ['sai', 'kiran', 'is', 'learing', 'nlp', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Exercise 2\n",
        "\n",
        "import re\n",
        "\n",
        "text = \"This is a sample sentence for regex tokenization.\";\n",
        "tokens = re.split(\"\\W+\", text)\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRMcSDPhl44W",
        "outputId": "67d471e5-60cf-42c5-c047-46152b92db7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['This', 'is', 'a', 'sample', 'sentence', 'for', 'regex', 'tokenization', '']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Exercise 3\n",
        "text = \"sai kiran is learing nlp.\";\n",
        "tokens = re.split(\"\\W+\", text)\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7A6_CNBmzBD",
        "outputId": "ed7c32c1-1111-4832-b028-a8081f1c6434"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['sai', 'kiran', 'is', 'learing', 'nlp', '']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Exercise 4\n"
      ],
      "metadata": {
        "id": "VPH2K_EronvF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}